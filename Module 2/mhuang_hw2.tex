\documentclass{article}
\linespread{1.3}
\usepackage[margin=50pt]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsthm, tikz, fancyhdr, graphicx, systeme}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\newcommand{\changefont}{\fontsize{15}{15}\selectfont}

\fancypagestyle{firstpageheader}{
  \fancyhead[R]{
    \changefont
    \parbox[t]{4cm}{ % Adjust width as needed
      Michael Huang\\
      EN.625.633.81\\
      Homework 2
    }
  }
}

\begin{document}

\thispagestyle{firstpageheader}
{\Large 

\section*{1.}

\subsection*{(a)}



\subsection*{(b)}



\subsection*{(c)}



\subsection*{(d)}



}

{\Large 

\section*{2.}

\subsection*{(a)} 



\subsection*{(b)}



}

{\Large 

\section*{3.}

Find $P(X^2 < Y < X)$ where $f(x,y) = 2x$ for $0 \le x, y \le 1$ [1].

We first establish the bounds -- given that we need \(X^2 < Y < X\), it is obvious that we must have \(0 < x < 1\). Given these two bounds, we can now establish the double integral for representing the joint pdf and evaluate:
\[
  P(X^2 < Y < X) = \int_0^1 \int_{x^2}^x 2x dy dx
\]
\[
  P(X^2 < Y < X) = \int_0^1 2x |_{x^2}^x dx
\]
\[
  P(X^2 < Y < X) = \int_0^1 2x^2 - 2x^3 dx
\]
\[
  P(X^2 < Y < X) = \frac{2x^3}{3} - \frac{2x^4}{4} |_0^1
\]
\[
  P(X^2 < Y < X) = (\frac{2}{3} - \frac{2}{4}) - (0 - 0) 
\]
\[
  \boxed{P(X^2 < Y < X) = \frac{1}{6}}
\]

}

{\Large 

\section*{4.}

\subsection*{(a)} 

Let's begin by calculating the marginal distributions from the table. \\
\[P(X = 1) = \frac{1}{12} + \frac{1}{6} + 0 = \frac{1}{4}\] \\
\[P(X = 2) = \frac{1}{6} + 0 + \frac{1}{3} = \frac{1}{2}\] \\
\[P(X = 3) = \frac{1}{12} + \frac{1}{6} + 0 = \frac{1}{4}\] \\
\[P(Y = 2) = \frac{1}{12} + \frac{1}{6} + \frac{1}{12} = \frac{1}{3}\] \\
\[P(Y = 3) = \frac{1}{6} + 0 + \frac{1}{6} = \frac{1}{3}\] \\
\[P(Y = 4) = 0 + \frac{1}{3} + 0 = \frac{1}{3}\] \\
Now, we can simply check for independence. We know that \(X\) and \(Y\) are independent if \(P(X = x, Y = y) = P(X = x) \cdot P(Y = y) \). Most values fulfill the condition, but we find that for \(Y = 3\) and \(X = 1\):
\[
  P(X = 1, Y = 3) = P(X = 1) \cdot P(Y = 3) 
\]
\[
  \frac{1}{6} = \frac{1}{4} \cdot \frac{1}{3}
\]
\[
  \frac{1}{6} \neq \frac{1}{12}
\]
So \(X\) and \(Y\) are not independent, and therefore dependent.

\subsection*{(b)}

We can do this by simply recreating the table, except multiply the marginals together. This ensures that they are independent, taking \(X = U\) and \(Y = V\):

\begin{center}

\begin{tabular}{c|ccc}

& $U=1$ & $U=2$ & $U=3$ \\

\hline

$V=2$ & $\frac{1}{4} \cdot \frac{1}{3}$ & $\frac{1}{2} \cdot \frac{1}{3}$ & $\frac{1}{4} \cdot \frac{1}{3}$ \\

$V=3$ & $\frac{1}{4} \cdot \frac{1}{3}$ & $\frac{1}{2} \cdot \frac{1}{3}$ & $\frac{1}{4} \cdot \frac{1}{3}$ \\

$V=4$ & $\frac{1}{4} \cdot \frac{1}{3}$ & $\frac{1}{2} \cdot \frac{1}{3}$ & $\frac{1}{4} \cdot \frac{1}{3}$

\end{tabular}

\end{center}


\begin{center}
\boxed{
\begin{tabular}{c|ccc}

& $U=1$ & $U=2$ & $U=3$ \\

\hline

$V=2$ & $\frac{1}{12}$ & $\frac{1}{6}$ & $\frac{1}{12}$ \\

$V=3$ & $\frac{1}{12}$ & $\frac{1}{6}$ & $\frac{1}{12}$ \\

$V=4$ & $\frac{1}{12}$ & $\frac{1}{6}$ & $\frac{1}{12}$

\end{tabular}
}
\end{center}



}

{\Large 

\section*{5.}



}

{\Large 

\section*{6.}

We are given the distribution of the average of the independent measurements as \(\bar{X} \sim N\left(\mu, \frac{25}{n}\right)\). We apply the Central Limit Theorem after standardizing the probability expression to \(N(0, 1)\) with \(Z = \frac{\bar{X} - \mu}{\sigma}\):
\[
  P(|\bar{X} - \mu| < 1)
\]
\[
  P(\frac{-1}{\sqrt{\frac{25}{n}}} < Z < \frac{1}{\sqrt{\frac{25}{n}}})
\]
\[
  P(-\frac{\sqrt{n}}{5} < Z < \frac{\sqrt{n}}{5})
\]
Since we are looking for tails on either side, we look for 2 symmetrical regions that give us the the remaining \(1 - 0.95 = 0.05\):
\[
  2\phi(\frac{\sqrt{n}}{5}) = 0.05
\]
\[
  \phi(\frac{\sqrt{n}}{5}) = 0.025
\]
\[
  \frac{\sqrt{n}}{5} = z_{0.025}
\]
We now do a lookup for the corresponding \(z\)-value, and substitute:
\[
  \frac{\sqrt{n}}{5} = 1.96
\]
\[
  \sqrt{n} = 9.8
\]
\[
  n = 96.04
\]
We round up as we need a whole number, which gives us the final answer that we need the number of measurements \(\boxed{n \geq 97}\).

}

{\Large 

\section*{7.}

\subsection*{(a)} 



\subsection*{(b)}



}

{\Large 

\section*{8.}

We are given the exponential distribution with probability density \(f(x|\lambda) = \lambda e^{-\lambda x}\). We first take the proper expression for the likelihood function corresponding to the \(n\) observed values of \(X\):
\[
  L(\lambda) = \prod_{i=1}^n \lambda e^{-\lambda x_i} 
\]
which we can easily simplify by multiplying to get
\[
  L(\lambda) = \lambda^n e^{-\lambda \sum_{i=1}^n x_i}
\]
We then proceed to take the log likelihood:
\[
  l(\lambda) = \ln(\lambda^n e^{-\lambda \sum_{i=1}^n x_i})
\]
\[
  l(\lambda) = n\ln(\lambda) - \lambda \sum_{i=1}^n x_i
\]
We then try to maximize this, so find a critical point by taking the derivative and setting equal to 0:
\[
  0 = \frac{dl}{d\lambda}
\]
\[
  0 = \frac{d}{d\lambda}(n\ln(\lambda) - \lambda \sum_{i=1}^n x_i)
\]
\[
  0 = \frac{n}{\lambda} - \sum_{i=1}^n x_i
\]
\[
  \sum_{i=1}^n x_i = \frac{n}{\lambda} 
\]
\[
  \lambda \sum_{i=1}^n x_i = n 
\]
\[
  \lambda = \frac{n}{\sum_{i=1}^n x_i} 
\]
We can also ensure that this is a maximum by taking the derivative again:
\[
  \frac{d^2l}{d\lambda^2} = \frac{d}{d\lambda}(\frac{n}{\lambda} - \sum_{i=1}^n x_i)
\]
\[
  \frac{d^2l}{d\lambda^2} = -\frac{n}{\lambda^2} - 0 = -\frac{n}{\lambda^2}
\]
The original probability density must be positive, so we know that \(\lambda > 0\) always. We see that this value of \(\frac{d^2l}{d\lambda^2} < 0\) for all \(\lambda > 0\), which means that this is indeed a maximum. We can now finally conclude that \(\hat{\lambda}_{\text{MLE}} = \frac{n}{\sum_{i=1}^n X_i} = \boxed{\frac{1}{\bar{X}}}\)

}

\end{document}