\documentclass{article}
\linespread{1.3}
\usepackage[margin=50pt]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsthm, tikz, fancyhdr, graphicx, systeme}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\newcommand{\changefont}{\fontsize{15}{15}\selectfont}

\fancypagestyle{firstpageheader}{
  \fancyhead[R]{
    \changefont
    \parbox[t]{4cm}{ % Adjust width as needed
      Michael Huang\\
      EN.625.633.81\\
      Homework 3
    }
  }
}

\begin{document}

\thispagestyle{firstpageheader}
{\Large 

\section*{1.}

\subsection*{(a)}

Given mean \(\mu = 2\) with the exponential distribution, we can directly plug in:

\[
  P(X > (s-t)) = e^{-\lambda \cdot (s-t)}
\]
\[
  P(X > 2) = e^{-\frac{1}{\mu} \cdot 2}
\]
\[
  P(X > 2) = e^{-\frac{1}{2} \cdot 2}
\]
\[
  P(X > 2) = e^{-1} = \boxed{0.36787944117}
\]

\subsection*{(b)}

We set up the equivalent conditional property expression:
\[
  P(X > 5 | X > 3) = \frac{P(X > 5 \cap X > 3)}{P(X > 3)}
\]
Logically, we know that if \(P(X > 5)\), \(P(X > 3)\) for sure, so we can remove the latter part, i.e. \(P(X > 5 \cap X > 3) = P(X > 5)\). Plugging back in:
\[
  P(X > 5 | X > 3) = \frac{P(X > 5)}{P(X > 3)}
\]
And now using the exponential pdf:
\[
  P(X > 5 | X > 3) = \frac{e^{-5\lambda}}{e^{-3\lambda}}
\]
\[
  P(X > 5 | X > 3) = \frac{e^{-5 \cdot \frac{1}{2}}}{e^{-3 \cdot \frac{1}{2}}}
\]
\[
  P(X > 5 | X > 3) = \frac{e^{\frac{-5}{2}}}{e^{\frac{-3}{2}}}
\]
\[
  P(X > 5 | X > 3) = e^{-1} = \boxed{0.36787944117}
\]

}
{\Large 

\section*{2.}

Given \(X \sim \text{Exp}(\lambda)\), we aim to prove that \(P(X \ge a+t | X \ge a) = P(X \ge t)\):
\begin{align*}
  P(X \ge a+t | X \ge a) &= \frac{P(X \ge a+t \cap X \ge a)}{P(X \ge a)} && \text{Conditional probability} \\
  &= \frac{P(X \ge a+t)}{P(X \ge a)} && \text{As above, } X \geq a+t \text{ implies } X \geq a && \\
  &= \frac{e^{-\lambda \cdot (a+t)}}{e^{-\lambda a}} && \text{Definition of exponential distribution} \\
  &= \frac{e^{-\lambda a} e^{-\lambda t}}{e^{-\lambda a}} \\
  &= e^{-\lambda t} \\
  &= P(X \ge t)
\end{align*}
as we sought to show.

}
{\Large 

\section*{3.}



}
{\Large 

\section*{4.}



}
{\Large 

\section*{5.}

\subsection*{(a)} 

We are given that \(N(5) = 2\), and Poisson process \(\lambda = 10\). As the arrival times are uniformly distributed, \(N(t) = n\) in time \([0, s]\) follows the Binomial with \(p = \frac{s}{t}\). We therefore can directly use the formula to calculate \(P(k = 2)\):
\[
  P(N(s) = l | N(t) = k) = \binom{k}{l} (\frac{s}{t})^l (1 - \frac{s}{t})^{k - l}
\]
\[
  P(N(s) = 2 | N(5) = 2) = \binom{2}{2} (\frac{2}{5})^2 (1 - \frac{2}{5})^{2 - 2}
\]
\[
  P(N(s) = 2 | N(5) = 2) = \binom{2}{2} (\frac{2}{5})^2 (\frac{3}{5})^0
\]
\[
  P(N(s) = 2 | N(5) = 2) = 1 \cdot \frac{4}{25} \cdot 1 = \boxed{\frac{4}{25}}
\]

\subsection*{(b)}

The probability that at least one customer arrived in the first two minutes is easier found by taking its complement, i.e. 1 - the probability that no customers arrived in the first two minutes:
\[
  P(N(s) = l | N(t) = k) = \binom{k}{l} (\frac{s}{t})^l (1 - \frac{s}{t})^{k - l}
\]
\[
  P(N(2) = 0 | N(5) = 2) = \binom{2}{0} (\frac{2}{5})^0 (1 - \frac{2}{5})^{2 - 0}
\]
\[
  P(N(2) = 0 | N(5) = 2) = 1 \cdot 1 \cdot (\frac{3}{5})^2
\]
\[
  P(N(2) = 0 | N(5) = 2) = \frac{9}{25}
\]
Taking the compliment, we see that 
\[
  P(N(2) \geq 1 | N(5) = 2) = 1 - \frac{9}{25} = \boxed{\frac{16}{25}}
\]

}
{\Large 

\section*{6.}

\subsection*{(a)} 

We are given Poisson \(N(t)\) with \(\lambda = 2\). To find \(P(N(2)=1, N(3)=4, N(5)=5)\), we can break this up into independent periods with how many events occur within each period, and then multiply. Let's begin: \\
1 event from \([0,1]\): \\
\[
  P[N(s) = n] = \frac{e^{-\lambda s} \cdot (\lambda s)^n}{n!}
\]
\[
  P[N(2) = 1] = \frac{e^{-2 \cdot 2} \cdot (2\cdot 2)^1}{1!}
\]
\[
  P[N(2) = 1] = \frac{e^{-4} \cdot 4^1}{1} = 4e^{-4}
\]
4-1 = 3 events from \([2,3]\): \\
\[
  P[N(3-2) = 3] = \frac{e^{-2 \cdot (3-2)} \cdot (2 \cdot (3-2))^3}{3!}
\]
\[
  P[N(1) = 3] = \frac{e^{-2} \cdot 2^3}{6} = \frac{4e^{-2}}{3}
\]
5-4 = 1 event from \([3,5]\): \\
\[
  P[N(5-3) = 1] = \frac{e^{-2 \cdot (5-3)} \cdot (2 \cdot (5-3))^1}{1!}
\]
\[
  P[N(2) = 1] = \frac{e^{-2 \cdot 2} \cdot (2 \cdot 2)^1}{1} = 4e^{-4}
\]
So finally, 
\[
  P(N(2)=1, N(3)=4, N(5)=5) = P(N(2)=1) \cdot P(N(3)-N(2)=3) \cdot P(N(5)-N(3)=1)
\]
\[ 
  = 4e^{-4} \cdot \frac{4e^{-2}}{3} \cdot 4e^{-4} = \frac{4 \cdot 4 \cdot 4}{3} e^{-4-2-4}
\]
\[
  = {\frac{64}{3}e^{-10}} = \boxed{0.00096853183}
\]

\subsection*{(b)}

To find \(P(N(4)=3 | N(2)=1, N(3)=2)\), we can first remove the \(N(2) = 1\) part because we know that \(N(3) = 2\) is the only relevant part given the independent time increments. Therefore, we just need to find \(P(N(4)=3 | N(3)=2)\):
\[
  P(N(4)=3 | N(3)=2) = P[N(4-3) = 3-2]
\]
\[
  P[N(s) = n] = \frac{e^{-\lambda s} \cdot (\lambda s)^n}{n!}
\]
\[
  P[N(1) = 1] = \frac{e^{-2 \cdot 1} \cdot (2 \cdot 1)^1}{1!}
\]
\[
  P[N(1) = 1] = \frac{e^{-2} \cdot 2^1}{1}
\]
\[
  P[N(1) = 1] = 2e^{-2} = \boxed{0.27067056647}
\]

\subsection*{(c)}

\begin{align*}
  E(N(4) | N(2) = 2) && \text{Given} \\
  E(N(4) - N(2) + N(2) | N(2)=2) && N(4) \text{ in  independent increments} \\
  E[N(4) - N(2) | N(2)=2] + E[N(2) | N(2)=2] && \text{Linearity of expectation}\\
  E[N(4) - N(2) | N(2)=2] + 2 && \text{Definition of expectation}\\
  E[N(4) - N(2)] + 2 && \text{Independent increments}\\
  E[N(4-2)] + 2 && \text{Definition of Poisson process}\\
  E[N(2)] + 2 \\
  \lambda \cdot 2 + 2 && \text{Definition of Poisson process}\\
  2 \cdot 2 + 2 \\
  4 + 2 = \boxed{6}\\
\end{align*}

}
{\Large 

\section*{7.}



}
{\Large 

\section*{8.}



}
{\Large 

\section*{9.}

\subsection*{(a)} 



\subsection*{(b)}



}


\end{document}